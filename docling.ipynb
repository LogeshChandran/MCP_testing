{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e381af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b98354",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --progress-bar off --no-warn-conflicts langchain-core langchain-huggingface langchain_milvus langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/5486:\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"\n",
    "# FILE_PATH = \"2408.pdf\"\n",
    "\n",
    "loader = DoclingLoader(file_path=FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceca7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[-1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs[:3]:\n",
    "    print(f\"- {d.page_content=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a05c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq \"unstructured[all-docs]\" pillow lxml pillow\n",
    "%pip install -Uq chromadb tiktoken\n",
    "%pip install -Uq langchain langchain-community langchain-openai langchain-groq\n",
    "%pip install -Uq python_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc74030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "output_path = \"C:\\\\Users\\\\LoChandran\\\\Desktop\\\\Python\\\\python_testing\\\\doc\\\\\"\n",
    "file_path = 'C:\\\\Users\\\\LoChandran\\\\Desktop\\\\Python\\\\python_testing\\\\2408.pdf'\n",
    "\n",
    "# Reference: https://docs.unstructured.io/open-source/core-functionality/chunking\n",
    "chunks = partition_pdf(\n",
    "    filename=file_path,\n",
    "    infer_table_structure=True,            # extract tables\n",
    "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
    "\n",
    "    # extract_image_block_types=[\"Image\"],   # Add 'Table' to list to extract image of tables\n",
    "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
    "\n",
    "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
    "\n",
    "    chunking_strategy=\"by_title\",          # or 'basic'\n",
    "    max_characters=10000,                  # defaults to 500\n",
    "    combine_text_under_n_chars=2000,       # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    "\n",
    "    # extract_images_in_pdf=True,          # deprecated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get 2 types of elements from the partition_pdf function\n",
    "set([str(type(el)) for el in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1afb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_community.document_loaders import TextLoader, ToMarkdownLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# # Step 1: Convert PDF to Markdown\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(\"2408.pdf\")\n",
    "# with open(\"output1.md\", \"w\", encoding='utf-8') as f:\n",
    "#     f.write(result.document.export_to_markdown(mark_annotations=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ef589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_converter = DocumentConverter()\n",
    "conv_res = doc_converter.convert(\"2408.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4359fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_res.document.export_to_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a89270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tables\n",
    "for table_ix, table in enumerate(conv_res.document.tables):\n",
    "    table_df: pd.DataFrame = table.export_to_dataframe()\n",
    "    print(f\"## Table {table_ix}\\n\\n\")\n",
    "    print(table_df.to_markdown())\n",
    "    break\n",
    "    # Save the table as csv\n",
    "    # element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix + 1}.csv\"\n",
    "    # log.info(f\"Saving CSV table to {element_csv_filename}\")\n",
    "    # table_df.to_csv(element_csv_filename)\n",
    "\n",
    "    # Save the table as html\n",
    "    # element_html_filename = output_dir / f\"{doc_filename}-table-{table_ix + 1}.html\"\n",
    "    # _log.info(f\"Saving HTML table to {element_html_filename}\")\n",
    "    # with element_html_filename.open(\"w\") as fp:\n",
    "    #     fp.write(table.export_to_html(doc=conv_res.document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e726412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | CPU.                             | Thread budget.   | native backend.TTS   | native backend.Pages/s   | native backend.Mem   | pypdfium backend.TTS   | pypdfium backend.Pages/s   | pypdfium backend.Mem   |\n",
      "|---:|:---------------------------------|:-----------------|:---------------------|:-------------------------|:---------------------|:-----------------------|:---------------------------|:-----------------------|\n",
      "|  0 | Apple M3 Max                     | 4                | 177 s 167 s          | 1.27 1.34                | 6.20 GB              | 103 s 92 s             | 2.18 2.45                  | 2.56 GB                |\n",
      "|  1 | (16 cores) Intel(R) Xeon E5-2690 | 16 4 16          | 375 s 244 s          | 0.60 0.92                | 6.16 GB              | 239 s 143 s            | 0.94 1.57                  | 2.42 GB                |\n"
     ]
    }
   ],
   "source": [
    "print(table_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Decompose the \"Content\" into clear and simple propositions, ensuring they are interpretable out of\n",
    "context.\n",
    "1. Split compound sentence into simple sentences. Maintain the original phrasing from the input\n",
    "whenever possible.\n",
    "2. For any named entity that is accompanied by additional descriptive information, separate this\n",
    "information into its own distinct proposition.\n",
    "3. Decontextualize the proposition by adding necessary modifier to nouns or entire sentences\n",
    "and replacing pronouns (e.g., \"it\", \"he\", \"she\", \"they\", \"this\", \"that\") with the full name of the\n",
    "entities they refer to.\n",
    "4. Present the results as a list of strings, formatted in JSON.\n",
    "\n",
    "Example:\n",
    "\n",
    "Input: Title: ¯Eostre. Section: Theories and interpretations, Connection to Easter Hares. Content:\n",
    "The earliest evidence for the Easter Hare (Osterhase) was recorded in south-west Germany in\n",
    "1678 by the professor of medicine Georg Franck von Franckenau, but it remained unknown in\n",
    "other parts of Germany until the 18th century. Scholar Richard Sermon writes that \"hares were\n",
    "frequently seen in gardens in spring, and thus may have served as a convenient explanation for the\n",
    "origin of the colored eggs hidden there for children. Alternatively, there is a European tradition\n",
    "that hares laid eggs, since a hare’s scratch or form and a lapwing’s nest look very similar, and\n",
    "both occur on grassland and are first seen in the spring. In the nineteenth century the influence\n",
    "of Easter cards, toys, and books was to make the Easter Hare/Rabbit popular throughout Europe.\n",
    "German immigrants then exported the custom to Britain and America where it evolved into the\n",
    "Easter Bunny.\"\n",
    "Output: [ \"The earliest evidence for the Easter Hare was recorded in south-west Germany in\n",
    "1678 by Georg Franck von Franckenau.\", \"Georg Franck von Franckenau was a professor of\n",
    "medicine.\", \"The evidence for the Easter Hare remained unknown in other parts of Germany until\n",
    "the 18th century.\", \"Richard Sermon was a scholar.\", \"Richard Sermon writes a hypothesis about\n",
    "the possible explanation for the connection between hares and the tradition during Easter\", \"Hares\n",
    "were frequently seen in gardens in spring.\", \"Hares may have served as a convenient explanation\n",
    "for the origin of the colored eggs hidden in gardens for children.\", \"There is a European tradition\n",
    "that hares laid eggs.\", \"A hare’s scratch or form and a lapwing’s nest look very similar.\", \"Both\n",
    "hares and lapwing’s nests occur on grassland and are first seen in the spring.\", \"In the nineteenth\n",
    "century the influence of Easter cards, toys, and books was to make the Easter Hare/Rabbit popular\n",
    "throughout Europe.\", \"German immigrants exported the custom of the Easter Hare/Rabbit to\n",
    "Britain and America.\", \"The custom of the Easter Hare/Rabbit evolved into the Easter Bunny in\n",
    "Britain and America.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd402095",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc44fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ('system',prompt,'user', \"Decompose the following\" + str(table_df.to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen3:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e71440f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = llm.invoke(input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2567089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this problem. The user wants me to decompose the given table into clear and simple propositions, following specific guidelines. First, I need to understand the input data. The table has rows with different CPU models and various metrics like Thread budget, TTS (Time to Scan?), Pages/s, Mem (Memory usage?), and some backend-specific metrics for native and pypdfium backends.\n",
      "\n",
      "The example provided earlier shows that the output should be a list of JSON strings, each representing a proposition. The key points from the example are splitting compound sentences, separating named entities with their descriptions into distinct propositions, decontextualizing by replacing pronouns with full names, and maintaining original phrasing as much as possible.\n",
      "\n",
      "Looking at the input table, the first row is for Apple M3 Max with 4 threads, and then various metrics. The second row is for an Intel Xeon E5-2690 with 16 cores, and different thread counts. Each metric has values for native backend and pypdfium backend. \n",
      "\n",
      "I need to break down each row into individual propositions. For example, the first row has \"Apple M3 Max\" as the CPU, with Thread budget 4, and then TTS values for native and pypdfium. Each of these should be separate propositions. Similarly, the second row has the Intel Xeon with multiple thread counts and metrics. \n",
      "\n",
      "I should check if there are any named entities that need to be split. For instance, \"Apple M3 Max\" is a named entity, but the example didn't split that, so maybe just keep the full name. The thread budget is a metric, so each entry should be a separate proposition. \n",
      "\n",
      "Also, the user mentioned decontextualizing by replacing pronouns, but in this data, there are no pronouns. So maybe that's not an issue here. The main task is to split each row into individual metrics, ensuring each is a separate string in the JSON list.\n",
      "\n",
      "Wait, the example had multiple sentences split into separate propositions. Here, each row has multiple columns. For each row, each column's data should be a separate proposition. For example, in the first row, \"Apple M3 Max\" is the CPU, then Thread budget is 4, then native backend TTS is 177 s 167 s, etc. Each of these should be a separate entry in the JSON list.\n",
      "\n",
      "But the user's example had the content split into multiple sentences, not just columns. So maybe the table is structured such that each row represents a different system, and each column's data is a separate proposition. However, the original input is a table, so the user might want each cell's data to be a proposition. \n",
      "\n",
      "Wait, the user's example input was a paragraph, and the output was a list of propositions. In this case, the input is a table. So perhaps each row represents a different system, and each column's data is a separate proposition. For example, for the first row, the CPU is Apple M3 Max, Thread budget is 4, etc. Each of these would be a proposition.\n",
      "\n",
      "But the user's example had the content split into sentences, so maybe the table's data should be split into individual entries. For instance, each row's data is split into separate propositions. However, the exact approach isn't clear. Let me re-read the user's instructions.\n",
      "\n",
      "The user says: \"Decompose the 'Content' into clear and simple propositions, ensuring they are interpretable out of context.\" The example had a paragraph split into multiple propositions. The input here is a table. The user might be expecting each row to be split into propositions based on the columns. \n",
      "\n",
      "For example, the first row has:\n",
      "\n",
      "- CPU: Apple M3 Max\n",
      "- Thread budget: 4\n",
      "- native backend.TTS: 177 s 16,7 s\n",
      "- native backend.Pages/s: 1.27 1.34\n",
      "- native backend.Mem: 6.20 GB\n",
      "- pypdfium backend.TTS: 103 s 92 s\n",
      "- pypdfium backend.Pages/s: 2.18 2.45\n",
      "- pypdfium backend.Mem: 2.56 GB\n",
      "\n",
      "Each of these would be a separate proposition. Similarly for the second row.\n",
      "\n",
      "So the output would be a list of strings, each representing a proposition. For example:\n",
      "\n",
      "\"Apple M3 Max is a CPU.\"\n",
      "\"Apple M3 Max has a thread budget of 4.\"\n",
      "\"Native backend TTS for Apple M3 Max is 177 s 167 s.\"\n",
      "And so on for each column.\n",
      "\n",
      "But the user's example had the content split into sentences, so maybe the table is the content, and each cell's data is a proposition. However, the user might have intended that each row represents a system, and each column's data is a separate proposition. Alternatively, maybe each row's data is split into individual metrics. \n",
      "\n",
      "But the user's example had the content as a paragraph, and the output was a list of propositions. So perhaps here, the table is the content, and each row is split into propositions based on the columns. \n",
      "\n",
      "Therefore, the answer should list each row's data as separate propositions, ensuring that each is clear and simple. For example:\n",
      "\n",
      "\"Apple M3 Max is a CPU.\"\n",
      "\"Apple M3 Max has a thread budget of 4.\"\n",
      "\"Native backend TTS for Apple M3 Max is 177 s 167 s.\"\n",
      "\"Native backend Pages/s for Apple M3 Max is 1.27 1.34.\"\n",
      "\"Native backend Mem for Apple M3 Max is 6.20 GB.\"\n",
      "\"Pypdfium backend TTS for Apple M3 Max is 103 s 92 s.\"\n",
      "\"Pypdfium backend Pages/s for Apple M3 Max is 2.18 2.45.\"\n",
      "\"Pypdfium backend Mem for Apple M3 Max is 2.56 GB.\"\n",
      "\n",
      "And similarly for the second row, but the CPU is (16 cores) Intel(R) Xeon E5-2690. Wait, the second row's CPU is \"(16 cores) Intel(R) Xeon E5-2690\". So that would be a proposition: \"(16 cores) Intel(R) Xeon E5-2690 is a CPU.\" Then the Thread budget is 16 4 16. Wait, the thread budget column for the second row is \"16 4 16\". That might be three different values. But the example had split sentences, not numbers. Maybe each number is a separate proposition? Or maybe the thread budget is a single value. \n",
      "\n",
      "Wait, the first row's thread budget is \"4\", and the second row's is \"16 4 16\". That might be three different thread counts. But the user's example had \"Thread budget.   | native backend.TTS   | native backend.Pages/s   | native backend.Mem   | pypdfium backend.TTS   | pypdfium backend.Pages/s   | pypdfium backend.Mem   |\" as columns. So the thread budget is a single column, but in the second row, the value is \"16 4 16\". Maybe that's three different thread counts for different scenarios. But the user's example didn't have such cases, so perhaps the approach is to split each row into propositions based on the columns, even if the values are multi-value.\n",
      "\n",
      "Alternatively, maybe the thread budget for the second row is 16, 4, 16. But how to represent that? Maybe each value is a separate proposition. However, the user's example didn't have such cases, so perhaps the user expects each cell's data to be a single proposition, even if it's a multi-value.\n",
      "\n",
      "But the user's example had the content split into multiple propositions, so maybe each cell is a proposition. For example, the first row's CPU is \"Apple M3 Max\", so the proposition is \"Apple M3 Max is a CPU.\" Similarly for each cell. \n",
      "\n",
      "But the user's example didn't split the data into cells but split sentences. So maybe the user is expecting that the table is the content, and each row's data is split into propositions. However, the exact approach isn't clear. \n",
      "\n",
      "Given the ambiguity, perhaps the best approach is to treat each row as a separate system, and each column's data as a proposition. For example:\n",
      "\n",
      "For the first row:\n",
      "\n",
      "- \"Apple M3 Max is a CPU.\"\n",
      "- \"Apple M3 Max has a thread budget of 4.\"\n",
      "- \"Native backend TTS for Apple M3 Max is 177 s 167 s.\"\n",
      "- \"Native backend Pages/s for Apple M3 Max is 1.27 1.34.\"\n",
      "- \"Native backend Mem for Apple M3 Max is 6.20 GB.\"\n",
      "- \"Pypdfium backend TTS for Apple M3 Max is 103 s 92 s.\"\n",
      "- \"Pypdfium backend Pages/s for Apple M3 Max is 2.18 2.45.\"\n",
      "- \"Pypdfium backend Mem for Apple M3 Max is 2.56 GB.\"\n",
      "\n",
      "Similarly for the second row, which has the CPU as \"(16 cores) Intel(R) Xeon E5-2690\". So:\n",
      "\n",
      "- \"(16 cores) Intel(R) Xeon E5-2690 is a CPU.\"\n",
      "- \"(16 cores) Intel(R) Xeon E5-2690 has a thread budget of 16 4 16.\"\n",
      "Wait, the thread budget for the second row is \"16 4 16\". That might be three different thread counts. But how to represent that? Maybe split into three propositions: \"16 cores\", \"4 threads\", \"16 threads\"? Or perhaps the thread budget is a single value with multiple entries. \n",
      "\n",
      "Alternatively, perhaps the thread budget is a single value, but the user input has a typo. However, the user's example didn't have such cases. Given that, perhaps the thread budget for the second row is \"16 4 16\", which could be three different values. So each value is a separate proposition. \n",
      "\n",
      "But the user's example didn't have such cases, so maybe the user expects that each cell's data is a single proposition. Therefore, for the second row, the thread budget is \"16 4 16\" as a single proposition: \"(16 cores) Intel(R) Xeon E5-2690 has a thread budget of 16 4 16.\"\n",
      "\n",
      "But that might not be ideal. However, without more context, it's safer to follow the example's approach, which split sentences into propositions. So the table's data is split into propositions per cell. \n",
      "\n",
      "Therefore, the final answer would be a list of JSON strings, each representing a proposition derived from the table's data.\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"propositions\": [\n",
      "    \"Apple M3 Max is a CPU.\",\n",
      "    \"Apple M3 Max has a thread budget of 4.\",\n",
      "    \"Native backend TTS for Apple M3 Max is 177 s 167 s.\",\n",
      "    \"Native backend Pages/s for Apple M3 Max is 1.27 1.34.\",\n",
      "    \"Native backend Mem for Apple M3 Max is 6.20 GB.\",\n",
      "    \"Pypdfium backend TTS for Apple M3 Max is 103 s 92 s.\",\n",
      "    \"Pypdfium backend Pages/s for Apple M3 Max is 2.18 2.45.\",\n",
      "    \"Pypdfium backend Mem for Apple M3 Max is 2.56 GB.\",\n",
      "    \"(16 cores) Intel(R) Xeon E5-2690 is a CPU.\",\n",
      "    \"(16 cores) Intel(R) Xeon E5-2690 has a thread budget of 16 4 16.\",\n",
      "    \"Native backend TTS for (16 cores) Intel(R) Xeon E5-2690 is 375 s 244 s.\",\n",
      "    \"Native backend Pages/s for (16 cores) Intel(R) Xeon E5-2690 is 0.60 0.92.\",\n",
      "    \"Native backend Mem for (16 cores) Intel(R) Xeon E5-2690 is 6.16 GB.\",\n",
      "    \"Pypdfium backend TTS for (16 cores) Intel(R) Xeon E5-2690 is 239 s 143 s.\",\n",
      "    \"Pypdfium backend Pages/s for (16 cores) Intel(R) Xeon E5-2690 is 0.94 1.57.\",\n",
      "    \"Pypdfium backend Mem for (16 cores) Intel(R) Xeon E5-2690 is 2.42 GB.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load into LangChain\n",
    "loader = TextLoader(\"output.md\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed936c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load into LangChain\n",
    "loader = ToMarkdownLoader(\"output1.md\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "docs1 = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fe976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[-5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[-9].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"2408.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "print(f\"{pages[index].metadata}\\n\")\n",
    "print(pages[index].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904aed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
